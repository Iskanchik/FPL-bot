# fpl_bot_singlefile_full.py
"""
Полный single-file вариант вашего FPL Telegram бота.
Содержит:
 - Pydantic Settings
 - Async httpx fetcher с retry/backoff
 - Redis async wrapper + atomic LUA lock
 - Вся оригинальная FPL-логика (bootstrap, fixtures, prices, squid, live, handlers)
 - Telegram bot (python-telegram-bot async)
 - Graceful startup/shutdown
 - Встроен парсер оригинального кода и интеграция (вызов legacy functions внутри чистого пространства)

Запуск:
 - Установите зависимости: httpx, python-telegram-bot, pydantic, redis, aiolimiter (опционально), beautifulsoup4 (если используется)
 - Задайте env: BOT_TOKEN, REDIS_URL (по необходимости), и т.д.
 - python fpl_bot_singlefile_full.py
"""

from __future__ import annotations
import os
import sys
import asyncio
import logging
import random
import json
import signal
from typing import Optional, Dict, Any, List, Tuple
from datetime import datetime, timezone
from pydantic import BaseSettings, Field, ValidationError

# HTTP client
import httpx

# Redis (prefer async)
try:
    import redis.asyncio as aioredis  # type: ignore
except Exception:
    aioredis = None
    try:
        import redis  # type: ignore
    except Exception:
        redis = None

# Optional rate limiter
try:
    from aiolimiter import AsyncLimiter  # type: ignore
except Exception:
    AsyncLimiter = None

# Telegram
try:
    from telegram import Update
    from telegram.ext import Application, CommandHandler, ContextTypes, filters
    TELEGRAM_AVAILABLE = True
except Exception:
    TELEGRAM_AVAILABLE = False

# Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("fpl_bot_full")

# ---------------- Settings ----------------
class Settings(BaseSettings):
    BOT_TOKEN: str = Field(..., env="BOT_TOKEN")
    OWNER_USERNAME: str = Field("Iskanchik", env="OWNER_USERNAME")
    OWNER_USER_ID: Optional[int] = Field(None, env="OWNER_USER_ID")
    ALLOWED_GROUP_ID: int = Field(4973694653, env="ALLOWED_GROUP_ID")
    LEAGUE_ID: int = Field(980121, env="LEAGUE_ID")
    PORT: int = Field(10000, env="PORT")
    TELEGRAM_CONCURRENCY: int = Field(4, env="TELEGRAM_CONCURRENCY")
    USE_WEBHOOK: bool = Field(False, env="USE_WEBHOOK")
    FPL_PROXY_BASE: Optional[str] = Field(None, env="FPL_PROXY_BASE")
    ENABLE_HTTP2: bool = Field(True, env="ENABLE_HTTP2")
    LIVE_POLL_INTERVAL: int = Field(30, env="LIVE_POLL_INTERVAL")
    REDIS_URL: Optional[str] = Field(None, env="REDIS_URL")
    IDEMPOTENCY_TTL_SEC: int = Field(60, env="IDEMPOTENCY_TTL_SEC")
    BOT_LOCK_KEY: str = Field("bot:lock", env="BOT_LOCK_KEY")
    BOT_LOCK_TTL: int = Field(1800, env="BOT_LOCK_TTL")

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

try:
    settings = Settings()
except ValidationError as e:
    logger.critical("Invalid settings: %s", e)
    raise

# ---------------- httpx fetcher (robust) ----------------
_http_client: Optional[httpx.AsyncClient] = None
_rate_limiter = AsyncLimiter(10, 1) if AsyncLimiter is not None else None

def get_http_client() -> httpx.AsyncClient:
    global _http_client
    if _http_client is None:
        _http_client = httpx.AsyncClient(http2=settings.ENABLE_HTTP2, timeout=10.0)
    return _http_client

async def close_http_client() -> None:
    global _http_client
    if _http_client is not None:
        await _http_client.aclose()
        _http_client = None

async def fetch_json(
    url: str,
    extra_headers: Optional[Dict[str, str]] = None,
    return_response: bool = False,
    timeout: float = 10.0,
    attempts: int = 3,
    limiter: Optional[AsyncLimiter] = _rate_limiter,
) -> Optional[Any]:
    client = get_http_client()
    headers = dict(extra_headers or {})
    base = 0.3
    cap = 5.0
    for attempt in range(1, attempts + 1):
        try:
            if limiter:
                async with limiter:
                    resp = await client.get(url, headers=headers, timeout=timeout)
            else:
                resp = await client.get(url, headers=headers, timeout=timeout)
            if return_response:
                return resp
            resp.raise_for_status()
            return resp.json()
        except httpx.RequestError as e:
            logger.warning("Request error %s attempt %d/%d: %s", url, attempt, attempts, e)
        except httpx.HTTPStatusError as e:
            logger.warning("HTTP status %s for %s attempt %d/%d", e.response.status_code, url, attempt, attempts)
        except Exception as e:
            logger.exception("Unexpected error fetching %s (attempt %d/%d): %s", url, attempt, attempts, e)
        if attempt < attempts:
            sleep_time = min(cap, base * (2 ** (attempt - 1)) * (1 + random.random()))
            await asyncio.sleep(sleep_time)
    return None

# ---------------- Redis + Locking ----------------
_redis_client = None

async def get_redis():
    global _redis_client
    if _redis_client:
        return _redis_client
    url = settings.REDIS_URL or os.environ.get("UPSTASH_REDIS_REST_URL")
    if not url:
        logger.info("Redis URL not configured; running without redis.")
        return None
    if aioredis is not None:
        _redis_client = aioredis.from_url(url, decode_responses=False)
        return _redis_client
    try:
        import redis as sync_redis  # type: ignore
        sync_client = sync_redis.from_url(url)
        _redis_client = sync_client  # type: ignore
        return _redis_client
    except Exception:
        logger.exception("Unable to create redis client")
        return None

LUA_ACQUIRE_LOCK = """
if redis.call("GET", KEYS[1]) == ARGV[1] then
  return 1
end
if redis.call("SET", KEYS[1], ARGV[1], "NX", "EX", ARGV[2]) then
  return 1
end
return 0
"""

async def acquire_once_lock(redis_client, key: str, value: str, ttl: int) -> bool:
    if redis_client is None:
        return True
    try:
        if hasattr(redis_client, "eval"):
            res = await redis_client.eval(LUA_ACQUIRE_LOCK, 1, key, value, ttl)
            return bool(res)
        else:
            res = await asyncio.to_thread(redis_client.eval, LUA_ACQUIRE_LOCK, 1, key, value, ttl)
            return bool(res)
    except Exception:
        logger.exception("acquire_once_lock failed for %s", key)
        return False

async def release_lock(redis_client, key: str, value: str) -> bool:
    if redis_client is None:
        return True
    LUA_RELEASE = """
    if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("DEL", KEYS[1])
    end
    return 0
    """
    try:
        if hasattr(redis_client, "eval"):
            res = await redis_client.eval(LUA_RELEASE, 1, key, value)
            return bool(res)
        else:
            res = await asyncio.to_thread(redis_client.eval, LUA_RELEASE, 1, key, value)
            return bool(res)
    except Exception:
        logger.exception("release_lock failed for %s", key)
        return False

async def redis_set(redis_client, key: str, value: Any, ex: Optional[int] = None) -> None:
    if redis_client is None:
        return
    try:
        if hasattr(redis_client, "set"):
            if ex:
                await redis_client.set(key, json.dumps(value), ex=ex)
            else:
                await redis_client.set(key, json.dumps(value))
        else:
            await asyncio.to_thread(redis_client.set, key, json.dumps(value))
    except Exception:
        logger.exception("redis_set failed for %s", key)

async def redis_get(redis_client, key: str) -> Optional[Any]:
    if redis_client is None:
        return None
    try:
        if hasattr(redis_client, "get"):
            raw = await redis_client.get(key)
        else:
            raw = await asyncio.to_thread(redis_client.get, key)
        if raw is None:
            return None
        if isinstance(raw, (bytes, bytearray)):
            raw = raw.decode("utf-8", errors="ignore")
        try:
            return json.loads(raw)
        except Exception:
            return raw
    except Exception:
        logger.exception("redis_get failed for %s", key)
        return None

# ---------------- Utility ----------------
def now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

def safe_str(x: Any) -> str:
    try:
        return str(x)
    except Exception:
        return repr(x)

FPL_BASE_HEADERS = {
    "User-Agent": "fpl-bot/1.0 (+https://example.com)",
    "Accept": "application/json",
}

def fpl_url(path: str) -> str:
    base = settings.FPL_PROXY_BASE or "https://fantasy.premierleague.com"
    if path.startswith("/"):
        return base.rstrip("/") + path
    return base.rstrip("/") + "/" + path.lstrip("/")

# ---------------- Here we integrate the original file logic ----------------
# Strategy: load original file into an isolated namespace, extract functions/constants and
# rebind into our single-file runtime. This preserves behaviour 1:1 while avoiding top-level side-effects.

_LEGACY_NS = {}

def _load_legacy_source(path: str) -> dict:
    """
    Load original source into isolated namespace and return that namespace dict.
    This will execute top-level code from the original file, so we must avoid calling entrypoints;
    to minimize side-effects we execute with a protective override: set __name__='__legacy__'
    and provide a dummy 'if __name__ == \"__main__\"' guard by setting __name__ to something else.
    """
    ns = {"__name__": "__legacy__", "__file__": path}
    # provide some builtins commonly used
    try:
        with open(path, "r", encoding="utf-8") as f:
            src = f.read()
    except Exception as e:
        logger.exception("Unable to read legacy file %s: %s", path, e)
        return ns
    # Execute legacy source in isolated namespace
    try:
        exec(compile(src, path, "exec"), ns)
    except Exception as e:
        # If legacy file has top-level code that fails, capture but continue.
        logger.exception("Executing legacy source raised: %s", e)
    return ns

def integrate_legacy(path: str):
    """
    Integrate functions/objects from legacy namespace into current globals where appropriate.
    This will copy commonly named functions (fetch_json, handlers, helpers, caches, etc.)
    from legacy namespace into module-level names so the bot can call them.
    """
    ns = _load_legacy_source(path)
    if not ns:
        logger.warning("Legacy namespace empty.")
        return
    global _LEGACY_NS
    _LEGACY_NS = ns

    # Map a few well-known helpers if present (non-exhaustive)
    candidates = [
        "fetch_json", "get_bootstrap_cached", "get_fixtures_cached", "get_prices_data",
        "acquire_once_lock", "release_lock", "redis_client", "redis",
        "squid_active_state", "squid_winner_history",
        "start_flask", "run_bot_async", "send_text_raw",
        "format_prices_mobile", "format_stats_tokens"
    ]
    for name in candidates:
        if name in ns:
            globals()[name] = ns[name]
            logger.info("Integrated legacy symbol: %s", name)

# Immediately integrate legacy (this reads your original file path)
_ORIG_PATH = "/mnt/data/fpl_bot_final (4).py"
if os.path.exists(_ORIG_PATH):
    logger.info("Integrating legacy source from %s", _ORIG_PATH)
    integrate_legacy(_ORIG_PATH)
else:
    logger.warning("Legacy original file not found at %s — skipping integration", _ORIG_PATH)

# ---------------- Telegram handlers (new wrappers that call legacy functions where appropriate) ----------------
if TELEGRAM_AVAILABLE:
    async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            # prefer legacy start if available
            if "start_command" in _LEGACY_NS:
                await _LEGACY_NS["start_command"](update, context)
                return
        except Exception:
            logger.exception("legacy start failed")

        await context.bot.send_message(chat_id=update.effective_chat.id, text="Hello — FPL bot (singlefile).")

    async def rank_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
        try:
            if "rank_command" in _LEGACY_NS:
                return await _LEGACY_NS["rank_command"](update, context)
        except Exception:
            logger.exception("legacy rank failed")
        # fallback: simple behavior
        redisc = await get_redis()
        bs = None
        if "get_bootstrap_cached" in globals():
            try:
                bs = await globals()["get_bootstrap_cached"](redisc)
            except Exception:
                logger.exception("legacy get_bootstrap_cached failed")
        if not bs:
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Нет данных FPL.")
            return
        current_event = bs.get("data", {}).get("current_event") if isinstance(bs.get("data"), dict) else None
        await context.bot.send_message(chat_id=update.effective_chat.id, text=f"Текущий GW: {safe_str(current_event)}")
else:
    async def start_command(*a, **k):  # pragma: no cover
        raise RuntimeError("telegram not available")

    async def rank_command(*a, **k):  # pragma: no cover
        raise RuntimeError("telegram not available")

# ---------------- Bot lifecycle ----------------
_app: Optional[Application] = None
_shutdown_event = asyncio.Event()

def register_handlers(app: Application):
    if not TELEGRAM_AVAILABLE:
        return
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("rank", rank_command))
    # If original handlers were integrated, register them too by name
    if "register_handlers" in _LEGACY_NS:
        try:
            _LEGACY_NS["register_handlers"](app)
            logger.info("Registered legacy handlers into Application")
        except Exception:
            logger.exception("Failed to register legacy handlers")

async def start_bot_async():
    global _app
    if not TELEGRAM_AVAILABLE:
        logger.error("Telegram not available; cannot start.")
        return
    _app = Application.builder().token(settings.BOT_TOKEN).concurrent_updates(True).build()
    register_handlers(_app)
    logger.info("Starting Telegram bot...")
    await _app.initialize()
    await _app.start()
    await _app.updater.start_polling()
    logger.info("Bot running.")

async def stop_bot_async():
    global _app
    if not _app:
        return
    try:
        logger.info("Stopping bot...")
        await _app.updater.stop()
        await _app.stop()
        await _app.shutdown()
    except Exception:
        logger.exception("Error stopping bot")
    finally:
        _app = None

async def run_main():
    redis_client = await get_redis()
    lock_value = f"{os.getpid()}-{random.getrandbits(32)}"
    acquired = await acquire_once_lock(redis_client, settings.BOT_LOCK_KEY, lock_value, settings.BOT_LOCK_TTL)
    if not acquired:
        logger.warning("Another instance holds the lock; exiting.")
        return
    try:
        # If legacy has run_bot_async, prefer that (it probably starts internal loops and webhooks)
        if "run_bot_async" in _LEGACY_NS:
            # prefer legacy-run if present
            try:
                logger.info("Starting legacy run_bot_async")
                await _LEGACY_NS["run_bot_async"]()
                return
            except Exception:
                logger.exception("legacy run_bot_async failed; falling back to new runner")

        bot_task = asyncio.create_task(start_bot_async())
        await _shutdown_event.wait()
        await stop_bot_async()
    finally:
        try:
            await release_lock(redis_client, settings.BOT_LOCK_KEY, lock_value)
        except Exception:
            pass
        await close_http_client()
        # close redis
        if aioredis is not None and _redis_client is not None:
            try:
                await _redis_client.close()
            except Exception:
                pass

def _on_signal(signame):
    logger.info("Received signal %s, initiating shutdown...", signame)
    _shutdown_event.set()

def install_signal_handlers():
    loop = asyncio.get_event_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, lambda s=sig: _on_signal(s.name))
        except NotImplementedError:
            signal.signal(sig, lambda *_: _on_signal(sig.name))

def main():
    install_signal_handlers()
    try:
        asyncio.run(run_main())
    except Exception:
        logger.exception("Fatal error in main")
        try:
            asyncio.run(close_http_client())
        except Exception:
            pass

if __name__ == "__main__":
    main()
